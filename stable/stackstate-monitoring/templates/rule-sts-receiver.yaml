{{- if .Values.rules.enabled }}
apiVersion: monitoring.coreos.com/v1
kind: PrometheusRule
metadata:
  name: stackstate-receiver-alerts
  labels:
    app: kube-prometheus-stack
{{- with .Values.rules.additionalLabels }}
{{ toYaml . | nindent 4 }}
{{- end }}
spec:
  groups:
    - name: stackstate-receiver-alerts
      rules:
        - alert: StackStateReceiverElementBudgetSaturation
          annotations:
            message: {{`The receiver in {{ $labels.namespace }}, path {{ $labels.path }}, has high element budget saturation level {{ $value }}.`}}
          expr: |
            stackstate_receiver_unique_element_passed_count{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} / stackstate_receiver_unique_element_passed_max{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} > 0.95
          for: 30m
          labels:
            severity: warning
            alert_resource: {{` '{{ $labels.service }}' `}}
        - alert: StackStateReceiverElementBudgetSaturationDropData
          annotations:
            message: {{`The receiver in {{ $labels.namespace }}, path {{ $labels.path }}, has high element budget saturation level {{ $value }}.`}}
          expr: |
            stackstate_receiver_unique_element_passed_count{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} / stackstate_receiver_unique_element_passed_max{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} >= 1
          for: 5m
          labels:
            severity: warning
            alert_resource: {{` '{{ $labels.service }}' `}}
        - alert: StackStateReceiverElementHourlyBudgetSaturation
          annotations:
            message: {{`The receiver in {{ $labels.namespace }}, path {{ $labels.path }}, has high element hourly budget saturation level {{ $value }}.`}}
          expr: |
            stackstate_receiver_element_create_passed_count{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} / stackstate_receiver_element_create_passed_max{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} > 0.95
          for: 30m
          labels:
            severity: warning
            alert_resource: {{` '{{ $labels.service }}' `}}
        - alert: StackStateReceiverElementHourlyBudgetSaturationDropData
          annotations:
            message: {{`The receiver in {{ $labels.namespace }}, path {{ $labels.path }}, has high element hourly budget saturation level {{ $value }}.`}}
          expr: |
            stackstate_receiver_element_create_passed_count{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} / stackstate_receiver_element_create_passed_max{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} > 1
          for: 5m
          labels:
            severity: warning
            alert_resource: {{` '{{ $labels.service }}' `}}
        - alert: StackStateReceiverExceedsMaxElementLimit
          annotations:
            message: {{`The receiver in {{ $labels.namespace }}, path {{ $labels.path }}, exceeds the limit for total number of {{ $labels.element_type }}.`}}
          expr: |
            stackstate_receiver_unique_element_passed_count{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} > stackstate_receiver_unique_element_passed_max{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"}
          for: 5m
          labels:
            severity: warning
            alert_resource: {{` '{{ $labels.service }}' `}}
        - alert: StackStateReceiverExceedsMaxHourlyElementLimit
          annotations:
            message: {{`The receiver in {{ $labels.namespace }}, path {{ $labels.path }}, exceeds the hourly limit for {{ $labels.element_type }}.`}}
          expr: |
            stackstate_receiver_element_create_passed_count{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"} > stackstate_receiver_element_create_passed_max{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"}
          for: 5m
          labels:
            severity: warning
            alert_resource: {{` '{{ $labels.service }}' `}}
        - alert: StackStateReceiverActiveRequestsGrowing
          annotations:
            message: {{`The \# of active requests for StackState receiver in {{ $labels.namespace }} has only been growing for the last 5 minutes.`}}
            runbook_url: https://www.notion.so/stackstate/Runbook-Receiver-increasing-active-requests-count-2486fb1560a44f85b107c5a69e29d66d
          expr: |
            sum(delta(akka_http_requests_active{namespace=~{{ .Values.rules.namespaceRegex | quote }}, app_component="receiver"}[1m])) by (namespace, service) > 0
          for: 5m
          labels:
            severity: critical
            alert_resource: {{` '{{ $labels.service }}' `}}
        - alert: StackStateReceiverLogVolumeRejected
          annotations:
            message: {{`StackState logs are rejected when one or more log sources (for example pods) are generating more logs than their budget based on the log retention and disk space available. Solutions:\n - The cause can be an increase in log volume for 1 or more sources, for example because debug logging was enabled for an application. The solution in that case is to reduce the log volume for these pods.\n      - If the log volume is legitimate and not expected to change either the available disk space can be increased or the retention can be decreased. See the Stackstate documentation for mitigations.`}}
          expr: |
            rate(stackstate_receiver_events_rejected_size{element_type="k8sLogs"}[1m]) > 0
          for: 5m
          labels:
            severity: warning
            alert_resource: {{` '{{ $labels.service }}' `}}
{{- end }}
